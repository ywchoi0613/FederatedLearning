{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ljKN_SsSe9cm",
        "outputId": "c8e0ca8b-489f-4006-fb6e-35eff77f1d69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.3487972021102905, Main Accuracy: 92.15%, Branch Accuracy: 91.62%\n",
            "Epoch 1, Loss: 0.10347329825162888, Main Accuracy: 97.83%, Branch Accuracy: 96.79%\n",
            "Epoch 2, Loss: 0.07394653558731079, Main Accuracy: 98.43%, Branch Accuracy: 97.73%\n",
            "Epoch 3, Loss: 0.05916569381952286, Main Accuracy: 98.75%, Branch Accuracy: 98.18%\n",
            "Epoch 4, Loss: 0.04864739999175072, Main Accuracy: 98.97%, Branch Accuracy: 98.47%\n",
            "Epoch 5, Loss: 0.038913026452064514, Main Accuracy: 99.19%, Branch Accuracy: 98.62%\n",
            "Epoch 6, Loss: 0.03509292006492615, Main Accuracy: 99.22%, Branch Accuracy: 98.75%\n",
            "Epoch 7, Loss: 0.033243004232645035, Main Accuracy: 99.27%, Branch Accuracy: 98.89%\n",
            "Epoch 8, Loss: 0.030967870727181435, Main Accuracy: 99.35%, Branch Accuracy: 99.02%\n",
            "Epoch 9, Loss: 0.02431274950504303, Main Accuracy: 99.50%, Branch Accuracy: 99.13%\n",
            "Epoch 10, Loss: 0.02086465060710907, Main Accuracy: 99.61%, Branch Accuracy: 99.23%\n",
            "Epoch 11, Loss: 0.01951160468161106, Main Accuracy: 99.62%, Branch Accuracy: 99.27%\n",
            "Epoch 12, Loss: 0.01679331064224243, Main Accuracy: 99.66%, Branch Accuracy: 99.38%\n",
            "Epoch 13, Loss: 0.015718553215265274, Main Accuracy: 99.67%, Branch Accuracy: 99.38%\n",
            "Epoch 14, Loss: 0.01519948709756136, Main Accuracy: 99.68%, Branch Accuracy: 99.52%\n",
            "Epoch 15, Loss: 0.01373152993619442, Main Accuracy: 99.72%, Branch Accuracy: 99.56%\n",
            "Epoch 16, Loss: 0.013706626370549202, Main Accuracy: 99.70%, Branch Accuracy: 99.52%\n",
            "Epoch 17, Loss: 0.012569830752909184, Main Accuracy: 99.74%, Branch Accuracy: 99.59%\n",
            "Epoch 18, Loss: 0.013073846697807312, Main Accuracy: 99.71%, Branch Accuracy: 99.56%\n",
            "Epoch 19, Loss: 0.011037448421120644, Main Accuracy: 99.78%, Branch Accuracy: 99.67%\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.229212\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2292364\n",
            "2.2291915\n",
            "2.2291808\n",
            "2.2291908\n",
            "2.2291832\n",
            "2.2292824\n",
            "2.2291827\n",
            "2.230754\n",
            "2.229181\n",
            "2.230689\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.229181\n",
            "2.2291808\n",
            "2.229193\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291827\n",
            "2.2291808\n",
            "2.2292082\n",
            "2.229181\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.257872\n",
            "2.2327867\n",
            "2.2291808\n",
            "2.229181\n",
            "2.2408032\n",
            "2.229181\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.229182\n",
            "2.2292051\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.229181\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291813\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2292287\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.229181\n",
            "2.2292056\n",
            "2.2291808\n",
            "2.2292733\n",
            "2.2291808\n",
            "2.2291825\n",
            "2.2291808\n",
            "2.2292569\n",
            "2.229181\n",
            "2.2291825\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291877\n",
            "2.2301042\n",
            "2.229181\n",
            "2.2291808\n",
            "2.229181\n",
            "2.2291808\n",
            "2.2291822\n",
            "2.229181\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.229181\n",
            "2.229181\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291813\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.229186\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2292323\n",
            "2.2291808\n",
            "2.229181\n",
            "2.2291808\n",
            "2.2305186\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.229181\n",
            "2.2291808\n",
            "2.24588\n",
            "2.2295704\n",
            "2.2295911\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291813\n",
            "2.2291849\n",
            "2.229215\n",
            "2.2291808\n",
            "2.229181\n",
            "2.2292237\n",
            "2.229181\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.229181\n",
            "2.2291808\n",
            "2.231322\n",
            "2.2337637\n",
            "2.2292302\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2802196\n",
            "2.2292137\n",
            "2.229181\n",
            "2.2291827\n",
            "2.2291825\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2292638\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.229208\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2544203\n",
            "2.2292142\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291982\n",
            "2.2291808\n",
            "2.2291813\n",
            "2.2292595\n",
            "2.2356794\n",
            "2.2291863\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291813\n",
            "2.2291808\n",
            "2.229181\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291856\n",
            "2.2291825\n",
            "2.2291813\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.233188\n",
            "2.229181\n",
            "2.2291815\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291815\n",
            "2.2291808\n",
            "2.2292063\n",
            "2.2291846\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291813\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.229181\n",
            "2.27652\n",
            "2.229252\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2300043\n",
            "2.229181\n",
            "2.2307692\n",
            "2.229206\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.229186\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291837\n",
            "2.229181\n",
            "2.2296603\n",
            "2.2291846\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.229181\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.229181\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.229181\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2292397\n",
            "2.229181\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2292347\n",
            "2.229181\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291813\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2416222\n",
            "2.2298498\n",
            "2.229181\n",
            "2.2291808\n",
            "2.229486\n",
            "2.229181\n",
            "2.229181\n",
            "2.2291808\n",
            "2.229182\n",
            "2.2291808\n",
            "2.2291837\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.229181\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291877\n",
            "2.2291808\n",
            "2.2293124\n",
            "2.2291853\n",
            "2.2291808\n",
            "2.2291822\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.229181\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291925\n",
            "2.2291832\n",
            "2.2292547\n",
            "2.2291808\n",
            "2.229182\n",
            "2.2291856\n",
            "2.229181\n",
            "2.2291808\n",
            "2.2396998\n",
            "2.2294369\n",
            "2.2291963\n",
            "2.2291808\n",
            "2.2291815\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.229185\n",
            "2.2291808\n",
            "2.2291822\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.229181\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.229343\n",
            "2.2291808\n",
            "2.229181\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291975\n",
            "2.2291808\n",
            "2.2292614\n",
            "2.229181\n",
            "2.2291832\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.230664\n",
            "2.229181\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2292237\n",
            "2.2291934\n",
            "2.2291813\n",
            "2.2291808\n",
            "2.229181\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.229181\n",
            "2.2482526\n",
            "2.2291808\n",
            "2.2291813\n",
            "2.2291808\n",
            "2.229217\n",
            "2.2291808\n",
            "2.2292483\n",
            "2.2291808\n",
            "2.2291837\n",
            "2.2291808\n",
            "2.2291965\n",
            "2.2291808\n",
            "2.229181\n",
            "2.2291808\n",
            "2.2291827\n",
            "2.2291827\n",
            "2.2292056\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2371879\n",
            "2.229182\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2782476\n",
            "2.229181\n",
            "2.2291822\n",
            "2.2291808\n",
            "2.2291834\n",
            "2.2291808\n",
            "2.2308643\n",
            "2.229181\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.235569\n",
            "2.2291813\n",
            "2.229181\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.229192\n",
            "2.2291808\n",
            "2.2343647\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.230967\n",
            "2.2291808\n",
            "2.229181\n",
            "2.2291808\n",
            "2.229181\n",
            "2.2291808\n",
            "2.229181\n",
            "2.2291808\n",
            "2.2292008\n",
            "2.2291808\n",
            "2.2291815\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291892\n",
            "2.2291808\n",
            "2.2291923\n",
            "2.2291808\n",
            "2.2291822\n",
            "2.2291808\n",
            "2.229181\n",
            "2.2291808\n",
            "2.229208\n",
            "2.2292213\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.229181\n",
            "2.2291808\n",
            "2.2291918\n",
            "2.2291808\n",
            "2.233897\n",
            "2.2416143\n",
            "2.2291813\n",
            "2.2291808\n",
            "2.229181\n",
            "2.229181\n",
            "2.2291958\n",
            "2.2291808\n",
            "2.2292237\n",
            "2.2300005\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2494411\n",
            "2.2732563\n",
            "2.2291813\n",
            "2.229195\n",
            "2.229182\n",
            "2.2291808\n",
            "2.2291813\n",
            "2.2291825\n",
            "2.2292042\n",
            "2.2291808\n",
            "2.229183\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.229181\n",
            "2.2291808\n",
            "2.2291815\n",
            "2.2291849\n",
            "2.2292018\n",
            "2.2291808\n",
            "2.2292988\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.230901\n",
            "2.231016\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.229213\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291882\n",
            "2.2291808\n",
            "2.2418792\n",
            "2.2292058\n",
            "2.2291822\n",
            "2.2291808\n",
            "2.2488554\n",
            "2.229181\n",
            "2.2291813\n",
            "2.2291808\n",
            "2.2291865\n",
            "2.2291815\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.229181\n",
            "2.2291808\n",
            "2.2292075\n",
            "2.2291808\n",
            "2.2291825\n",
            "2.229181\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.229181\n",
            "2.2291808\n",
            "2.2291865\n",
            "2.2291808\n",
            "2.2291818\n",
            "2.2291808\n",
            "2.229181\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.229212\n",
            "2.229181\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291887\n",
            "2.2291813\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.229183\n",
            "2.2291808\n",
            "2.2291877\n",
            "2.2291808\n",
            "2.2291825\n",
            "2.2291808\n",
            "2.2293117\n",
            "2.2291808\n",
            "2.234188\n",
            "2.2434256\n",
            "2.2296014\n",
            "2.2291808\n",
            "2.2292795\n",
            "2.2291815\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2292275\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.229181\n",
            "2.2291808\n",
            "2.2291818\n",
            "2.2291906\n",
            "2.229181\n",
            "2.229181\n",
            "2.2291813\n",
            "2.2291808\n",
            "2.2291846\n",
            "2.2321703\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.229181\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.229181\n",
            "2.2291808\n",
            "2.229181\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.229181\n",
            "2.2291808\n",
            "2.229181\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.229181\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291837\n",
            "2.2291808\n",
            "2.2291849\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2292264\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2628725\n",
            "2.2873526\n",
            "2.2292192\n",
            "2.233903\n",
            "2.2291899\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.262925\n",
            "2.229198\n",
            "2.229181\n",
            "2.2291808\n",
            "2.230623\n",
            "2.229624\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.229181\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.229181\n",
            "2.2291808\n",
            "2.2310479\n",
            "2.2291815\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291834\n",
            "2.2291808\n",
            "2.2302306\n",
            "2.229187\n",
            "2.2291906\n",
            "2.229181\n",
            "2.2403603\n",
            "2.2291808\n",
            "2.229203\n",
            "2.2292252\n",
            "2.2303672\n",
            "2.250755\n",
            "2.229181\n",
            "2.2291808\n",
            "2.2291815\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291813\n",
            "2.2291808\n",
            "2.2291892\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291813\n",
            "2.2291808\n",
            "2.229219\n",
            "2.2291808\n",
            "2.2292404\n",
            "2.2291808\n",
            "2.229256\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.229181\n",
            "2.2291808\n",
            "2.2293298\n",
            "2.2291808\n",
            "2.2292674\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2293046\n",
            "2.229181\n",
            "2.2292032\n",
            "2.2291808\n",
            "2.2733245\n",
            "2.229182\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.232579\n",
            "2.2291808\n",
            "2.2291846\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2292824\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.229181\n",
            "2.2291825\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2294774\n",
            "2.2291808\n",
            "2.229181\n",
            "2.2291808\n",
            "2.229181\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291923\n",
            "2.2291899\n",
            "2.2291808\n",
            "2.229181\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2292118\n",
            "2.229181\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291813\n",
            "2.2291808\n",
            "2.229181\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2292266\n",
            "2.2291808\n",
            "2.229265\n",
            "2.2291808\n",
            "2.2291834\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.229183\n",
            "2.2291808\n",
            "2.2741828\n",
            "2.2291827\n",
            "2.229181\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2295177\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.229181\n",
            "2.229181\n",
            "2.2292955\n",
            "2.2291808\n",
            "2.2291865\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.264292\n",
            "2.2291808\n",
            "2.2484012\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2304688\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.229181\n",
            "2.2291808\n",
            "2.2293568\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291822\n",
            "2.2291808\n",
            "2.229181\n",
            "2.2292051\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2292151\n",
            "2.2293391\n",
            "2.2291846\n",
            "2.229181\n",
            "2.229181\n",
            "2.2291808\n",
            "2.2853332\n",
            "2.229181\n",
            "2.2291975\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2294014\n",
            "2.2291808\n",
            "2.2451704\n",
            "2.2291808\n",
            "2.2293038\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2343936\n",
            "2.2291808\n",
            "2.2291927\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291813\n",
            "2.229181\n",
            "2.2291808\n",
            "2.2291882\n",
            "2.2291808\n",
            "2.2294025\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.229185\n",
            "2.2291808\n",
            "2.2291987\n",
            "2.2291808\n",
            "2.230126\n",
            "2.2291822\n",
            "2.229181\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291818\n",
            "2.2291808\n",
            "2.2292042\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2292192\n",
            "2.2291808\n",
            "2.235706\n",
            "2.2291808\n",
            "2.2293172\n",
            "2.2768254\n",
            "2.2291822\n",
            "2.2291808\n",
            "2.2291849\n",
            "2.232134\n",
            "2.2478032\n",
            "2.2757573\n",
            "2.2317803\n",
            "2.2291808\n",
            "2.2291858\n",
            "2.229181\n",
            "2.229181\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.2291808\n",
            "2.229181\n",
            "2.2291808\n",
            "2.2291892\n",
            "2.2291808\n",
            "2.2736728\n",
            "2.2291808\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-308a7b7f1edb>\u001b[0m in \u001b[0;36m<cell line: 120>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfast_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m     \u001b[0mexit_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-308a7b7f1edb>\u001b[0m in \u001b[0;36mfast_inference\u001b[0;34m(model, x, threshold)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfast_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0msoftmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0mmain_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbranch_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbranch_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmain_output\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0mlayout_map_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_subclass_model_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layout_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc_in_current_and_subclasses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1147\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m                 ):\n\u001b[0;32m-> 1149\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_keras_call_info_injected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-308a7b7f1edb>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mbranch_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbranch_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# branch output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mmain_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# main output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1147\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m                 ):\n\u001b[0;32m-> 1149\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_keras_call_info_injected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    239\u001b[0m                 )\n\u001b[1;32m    240\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m         \u001b[0;31m# Broadcast kernel to inputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/weak_tensor_ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_auto_dtype_conversion_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0mbound_arguments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mbound_arguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1261\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, output_type, name)\u001b[0m\n\u001b[1;32m   3840\u001b[0m             a, b, adj_x=adjoint_a, adj_y=adjoint_b, Tout=output_type, name=name)\n\u001b[1;32m   3841\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3842\u001b[0;31m         return gen_math_ops.mat_mul(\n\u001b[0m\u001b[1;32m   3843\u001b[0m             a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[1;32m   3844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   6169\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6170\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6171\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   6172\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_a\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_b\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6173\u001b[0m         transpose_b)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import time\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 데이터 로드 및 전처리\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255\n",
        "test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "# B-LeNet 모델 정의\n",
        "class BLeNet(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(BLeNet, self).__init__()\n",
        "        self.conv1 = tf.keras.layers.Conv2D(6, (5,5), activation='relu')\n",
        "        self.pool1 = tf.keras.layers.MaxPooling2D((2,2))\n",
        "        self.conv2 = tf.keras.layers.Conv2D(16, (5,5), activation='relu')\n",
        "        self.pool2 = tf.keras.layers.MaxPooling2D((2,2))\n",
        "        self.flatten = tf.keras.layers.Flatten()\n",
        "        self.dense1 = tf.keras.layers.Dense(120, activation='relu')\n",
        "        self.dense2 = tf.keras.layers.Dense(84, activation='relu')\n",
        "        self.dense3 = tf.keras.layers.Dense(10, activation='softmax')\n",
        "        self.branch_dense = tf.keras.layers.Dense(10, activation='softmax')\n",
        "\n",
        "    def call(self, x):\n",
        "        x1 = self.conv1(x)\n",
        "        x = self.pool1(x1)\n",
        "        x2 = self.conv2(x)\n",
        "        x = self.pool2(x2)\n",
        "        branch_output = self.branch_dense(self.flatten(x1))  # branch output\n",
        "        x = self.flatten(x)\n",
        "        x = self.dense1(x)\n",
        "        x = self.dense2(x)\n",
        "        main_output = self.dense3(x)  # main output\n",
        "        return main_output, branch_output\n",
        "\n",
        "# 모델 초기화\n",
        "model = BLeNet()\n",
        "\n",
        "# 손실 함수 설정\n",
        "loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
        "\n",
        "# 옵티마이저 설정\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.99, beta_2=0.999)\n",
        "\n",
        "# 가중치 설정\n",
        "weights = np.array([1.0, 0.3], dtype=np.float32)\n",
        "\n",
        "# 가중치가 적용된 손실 함수\n",
        "def weighted_loss(y_true, y_pred, weights):\n",
        "    loss = tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n",
        "    return tf.reduce_mean(loss * weights)\n",
        "\n",
        "# 훈련 함수 정의\n",
        "@tf.function\n",
        "def train_step(images, labels, model, loss_fn, optimizer, weights):\n",
        "    with tf.GradientTape() as tape:\n",
        "        main_output, branch_output = model(images)\n",
        "        loss = weighted_loss(labels, main_output, weights[0]) + weighted_loss(labels, branch_output, weights[1])\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "    # 정확도 계산\n",
        "    correct_main = tf.equal(tf.argmax(main_output, 1), tf.argmax(labels, 1))\n",
        "    correct_branch = tf.equal(tf.argmax(branch_output, 1), tf.argmax(labels, 1))\n",
        "    accuracy_main = tf.reduce_mean(tf.cast(correct_main, tf.float32))\n",
        "    accuracy_branch = tf.reduce_mean(tf.cast(correct_branch, tf.float32))\n",
        "\n",
        "    return loss, accuracy_main, accuracy_branch\n",
        "\n",
        "# 훈련 데이터셋을 사용하여 모델 훈련\n",
        "for epoch in range(20):  # 20 epoch 동안 훈련\n",
        "    total_loss = 0\n",
        "    total_accuracy_main = 0\n",
        "    total_accuracy_branch = 0\n",
        "    num_batches = 0\n",
        "    for i in range(0, len(train_images), 32):  # 32의 배치 크기로 훈련\n",
        "        images = train_images[i:i+32]\n",
        "        labels = train_labels[i:i+32]\n",
        "        loss, accuracy_main, accuracy_branch = train_step(images, labels, model, loss_fn, optimizer, weights)\n",
        "        total_loss += loss\n",
        "        total_accuracy_main += accuracy_main\n",
        "        total_accuracy_branch += accuracy_branch\n",
        "        num_batches += 1\n",
        "\n",
        "    avg_loss = total_loss / num_batches\n",
        "    avg_accuracy_main = total_accuracy_main / num_batches\n",
        "    avg_accuracy_branch = total_accuracy_branch / num_batches\n",
        "    print(f\"Epoch {epoch}, Loss: {avg_loss.numpy()}, Main Accuracy: {avg_accuracy_main.numpy()*100:.2f}%, Branch Accuracy: {avg_accuracy_branch.numpy()*100:.2f}%\")\n",
        "\n",
        "# 빠른 추론 함수\n",
        "def fast_inference(model, x, threshold):\n",
        "    softmax = tf.keras.layers.Softmax()\n",
        "    main_output, branch_output = model(x)\n",
        "    outputs = [branch_output, main_output]\n",
        "\n",
        "    # 각 exit에서의 출력을 검사\n",
        "    for i, output in enumerate(outputs):\n",
        "        softmax_output = softmax(output)  # y\n",
        "        entropy = -np.sum(softmax_output * np.log(softmax_output + 1e-20))\n",
        "        print(entropy)\n",
        "        # 엔트로피가 임계값보다 낮으면, 해당 exit의 출력을 반환\n",
        "        if entropy < threshold:\n",
        "            return np.argmax(softmax_output.numpy(), axis=-1), i\n",
        "\n",
        "    # 모든 exit를 통과한 후, 마지막 exit의 출력을 반환\n",
        "    return np.argmax(softmax(main_output).numpy(), axis=-1), len(outputs) - 1\n",
        "\n",
        "# 임계값 설정\n",
        "threshold = 0.025 #2.23\n",
        "\n",
        "# 테스트 데이터셋을 사용하여 빠른 추론 수행 및 시간 측정\n",
        "start_time = time.time()\n",
        "exit_counts = np.zeros(2)\n",
        "total_correct = 0\n",
        "\n",
        "for i in range(len(test_images)):\n",
        "    prediction, exit = fast_inference(model, np.expand_dims(test_images[i], axis=0), threshold)\n",
        "    exit_counts[exit] += 1\n",
        "    if prediction == np.argmax(test_labels[i]):\n",
        "        total_correct += 1\n",
        "\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "\n",
        "# 정확도, 시간, 각 exit에서의 비율 출력\n",
        "accuracy = total_correct / len(test_images)\n",
        "exit_ratios = exit_counts / len(test_images)\n",
        "\n",
        "print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
        "print(f\"Time: {total_time:.2f} seconds\")\n",
        "print(f\"Exit ratios: {exit_ratios}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}